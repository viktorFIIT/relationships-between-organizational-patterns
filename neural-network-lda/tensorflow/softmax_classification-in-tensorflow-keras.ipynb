{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e8714c",
   "metadata": {},
   "source": [
    "**Implementation of Softmax Regression (Classification) as Multi-layer Perceptron in TensorFlow 2**\n",
    "\n",
    "This model is designed to classify attributes of the patterns / pattern languages or sequences to a set of the classes. Class with a highest probability is a prediction for a given sample in training dataset.\n",
    "\n",
    "Because dataset of the attributes is still being consulted, sample dataset with 11 independent variables is provided. Dependent variable is a label, class. There are 10 classes in a dataset, classes 5, 6 and 7 are most present (some patterns are used more often than the others).\n",
    "\n",
    "Currently these options are being considered:\n",
    "- term frequencies (tf)\n",
    "- inverse frequencies (tf-idf)\n",
    "- probabilities (from our work Modelling of Organizational Pattern Sequences in Bayesian Network)\n",
    "- Table 1 from section 3.3. in http://www2.fiit.stuba.sk/~vranic/pub/ExtractingRelations.pdf\n",
    "\n",
    "<ins>Example how to interpret output from this Neural network</ins>:\n",
    "\n",
    "Let's say prediction for a first row in our training dataset is a vector of values: (0.08568677, 0.09945365, 0.08751229, 0.09474804, 0.1098659 , 0.12171782, 0.10679027, 0.10450635, 0.10343555, 0.08628327). This means first row in dataset has been assigned to class 6 because of its highest probability (0.1211782). Class 6 can represent organizational pattern, organizational pattern language or sequence of organizational patterns.\n",
    "\n",
    "Please note that prediction is correct if it is consistent with actual class. Accuracy of the model is one of the metrics used to evaluate this behavior.\n",
    "\n",
    "For further reference see: https://d2l.ai/chapter_linear-networks/softmax-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039b97d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\vikto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3080\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3081\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:101\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:4554\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:4562\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m y_test \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[0;32m     37\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     38\u001b[0m           validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\vikto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:3966\u001b[0m, in \u001b[0;36mNDFrame.__delitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3961\u001b[0m             deleted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m deleted:\n\u001b[0;32m   3963\u001b[0m     \u001b[38;5;66;03m# If the above loop ran and didn't delete anything because\u001b[39;00m\n\u001b[0;32m   3964\u001b[0m     \u001b[38;5;66;03m# there was no match, this call should raise the appropriate\u001b[39;00m\n\u001b[0;32m   3965\u001b[0m     \u001b[38;5;66;03m# exception:\u001b[39;00m\n\u001b[1;32m-> 3966\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3967\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39midelete(loc)\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;66;03m# delete from the caches\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\vikto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3082\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3081\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tolerance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_tolerance(tolerance, np\u001b[38;5;241m.\u001b[39masarray(key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# we can also use probabilities instead of n-gram frequencies (tf-idf or binary encoded)\n",
    "frequencies = pd.read_csv('dataset.csv', sep = ';')\n",
    "train, val, test = np.split(frequencies.sample(frac=1, random_state=42), [int(.6*len(frequencies)), int(.8*len(frequencies))])\n",
    "\n",
    "# classes 5, 6 and 7 are most present\n",
    "num_classes = np.bincount(train['pattern']) \n",
    "\n",
    "model = Sequential([\n",
    "    Dense(11, activation='relu'),\n",
    "    Dense(350, activation='relu'), \n",
    "    Dense(50, activation='relu'), \n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "y_train = train[\"pattern\"]\n",
    "y_test = test[\"pattern\"]\n",
    "del train[\"pattern\"]\n",
    "del test[\"pattern\"]\n",
    "del val[\"pattern\"]\n",
    "\n",
    "model.fit(train, y_train, epochs=10, \n",
    "          batch_size=250, verbose=1,\n",
    "          validation_split=0.2)\n",
    "\n",
    "results = model.evaluate(test, y_test, verbose = 1)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "# some classes are present more than the others. Our task here would be to classify imbalanced data\n",
    "# 1. we normalize them\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train)\n",
    "val_features = scaler.transform(val)\n",
    "test_features = scaler.transform(test)\n",
    "\n",
    "train_labels = np.array(y_train)\n",
    "bool_train_labels = train_labels != 0\n",
    "\n",
    "# 2. then we're able to visualize their distributions\n",
    "\n",
    "pos_df = pd.DataFrame(train_features[ bool_train_labels], columns=train.columns)\n",
    "neg_df = pd.DataFrame(train_features[~bool_train_labels], columns=train.columns)\n",
    "\n",
    "sns.jointplot(x=pos_df['freq3'], y=pos_df['freq5'], kind='hex', xlim=(-5,5), ylim=(-5,5))\n",
    "\n",
    "model.summary()\n",
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81bade0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
