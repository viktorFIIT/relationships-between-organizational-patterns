{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e8714c",
   "metadata": {},
   "source": [
    "**Classification of pattern sequences to similar groups - Softmax Regression (Classification) as Multi-layer Perceptron in TensorFlow 2**\n",
    "\n",
    "This neural network is designed to classify organizational patterns / pattern languages or organizational pattern sequences. Index of a prediction from a Softmax regression with a highest probability is your classified organizational pattern. Our task was to find whether we can calculate probabilities (likelihood) of the organizational patterns based on the frequencies of the words with which they have been documented.\n",
    "\n",
    "This work is a continuation of the research of Waseeb et al.: Extracting Relations Between Organizational Patterns Using Association Mining, which you can find here: http://www2.fiit.stuba.sk/~vranic/pub/ExtractingRelations.pdf . Dataset we're working on is similar to one page 4. Table 1 titled as \"A matrix sample values for n-gram existence against org. patterns\".\n",
    "\n",
    "Sample dataset with frequencies of the 11 bigrams found in textual descriptions of the organizational patterns from http://www.orgpatterns.com/ has been provided.\n",
    "\n",
    "Example:\n",
    "\n",
    "Train dataset consists of the frequencies of the bigrams for 18 organizational patterns. Output from this Artificial Neural Network is vector for a pattern with frequencies from a validation and test dataset with as many components as patterns in training dataset. \n",
    "\n",
    "(x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18)\n",
    "\n",
    "where xi is output from a softmax regression and it's a likelihood of the pattern given observed frequencies.\n",
    "Biggest value - highest probability from this vector is a classification of the set of the bigram frequencies to a given pattern.\n",
    "\n",
    "Training test and validation datasets consist of the same 11 bigrams, or attributes. Validation dataset should be used to optimalize hyperparameters (parameters which are not trained during computation of this ANN) and test dataset shall be used only once.\n",
    "\n",
    "Please note that prediction is correct if it is consistent with an actual class. Accuracy of the model is one of the metrics used to evaluate this behavior.\n",
    "\n",
    "Theory behind this can be found in a book Dive into Deep Learning: https://d2l.ai/chapter_linear-networks/softmax-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039b97d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "train_df = pd.read_excel('bigram-pattern-frequencies-train.xlsx', engine='openpyxl')\n",
    "val_df = pd.read_excel('bigram-pattern-frequencies-val.xlsx', engine='openpyxl')\n",
    "test_df = pd.read_excel('bigram-pattern-frequencies-test.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079eb75",
   "metadata": {},
   "source": [
    "**Normalization of organizational patterns bigram frequencies**\n",
    "\n",
    "Why? Because some of the bigrams (independent variables, attributes X) have higher frequencies than the others. This means they are used often in pattern descriptions than those used lest. We will normalize these attributes so they contribute equally to the model training process. Normalization is often a must be to get acceptable results from machine learning or deep learning models.\n",
    "\n",
    "Because some of the bigrams are used more often than the others they differ in a (statistical) variance. This means they must be normalized because of this fact too. It's not very good to increase learning rate (as one of the hyperparameters of this neural network) when attributes are not normalized before. This could lead to divergency, when we wouldn't be able to find best parameters from this training process.\n",
    "\n",
    "Good news is we don't have to weigth our labels (indexes representing organizational patterns) since each class (organizational pattern) is represent once in our working dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff28b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_patterns = 19\n",
    "\n",
    "train_scaler = StandardScaler()\n",
    "train_without_target = train_df.drop(['PatternIndex'], axis=1)\n",
    "train_without_pattern_name = train_without_target.drop(['OrganizationalPattern'], axis=1)\n",
    "train_features = train_scaler.fit(train_without_pattern_name.values)\n",
    "\n",
    "X_train = pd.DataFrame(train_scaler.transform(train_df.iloc[:, 1:-1].values))\n",
    "y_train = to_categorical(train_df.iloc[:,-1].values, number_of_patterns) # hot-encoding label (pattern index) for softmax regression\n",
    "\n",
    "val_scaler = StandardScaler()\n",
    "val_without_target = val_df.drop(['PatternIndex'], axis=1)\n",
    "val_without_pattern_name = val_without_target.drop(['OrganizationalPattern'], axis=1)\n",
    "val_features = val_scaler.fit(val_without_pattern_name.values)\n",
    "\n",
    "X_val = pd.DataFrame(val_scaler.transform(val_df.iloc[:, 1:-1].values))\n",
    "y_val = to_categorical(val_df.iloc[:,-1].values, number_of_patterns)\n",
    "\n",
    "test_scaler = StandardScaler()\n",
    "test_without_target = test_df.drop(['PatternIndex'], axis=1)\n",
    "test_without_pattern_name = test_without_target.drop(['OrganizationalPattern'], axis=1)\n",
    "test_features = test_scaler.fit(test_without_pattern_name.values)\n",
    "\n",
    "X_test = pd.DataFrame(test_scaler.transform(test_df.iloc[:, 1:-1].values))\n",
    "y_test = to_categorical(test_df.iloc[:,-1].values, number_of_patterns)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6ef13",
   "metadata": {},
   "source": [
    "**Softmax Regression - Classification of the patterns based on the n-gram frequencies**\n",
    "\n",
    "These functions are those components in neural network which are responsible for output generation. Combination of linear functions (layers of the ANN without these functions perform affine transformations only) is stil a linear function. That's why we need non-linear activation function. Non-linear activation functions help us to take advantage of the GPU processing capabilities.\n",
    "\n",
    "ReLU is one of the standard activation functions used in the neural networks. Softmax is activation function too. Number passed as argument to the constructor of the layer of our Artificial Neural Network is number of perceptrons on this layer. Dropout layer is used as regularization technique to eliminate overfitting of the model on training dataset.\n",
    "\n",
    "First dense layer is our input layer, or layer to consume our dataset. It has 11 neurons, because we have 11 bigrams in our training dataset. Last layer is output layer of this neural network. All layers between are hidden layers of this network. All layers are fully connected layers of this Multi-layer perceptron.\n",
    "\n",
    "What we're doing here? Well, we go through these steps for 100 epochs:\n",
    "\n",
    " 1. we pass here our dataset\n",
    " 2. we declare ANN as MLP. See https://d2l.ai/chapter_multilayer-perceptrons/index.html\n",
    " 3. we declare optimizer which we want to use. It's Adam, best in class: https://arxiv.org/pdf/1412.6980.pdf\n",
    " 4. we work with-minibatches. So we optimalize our parameters after passing each 4 rows in our dataset.\n",
    " 5. we perform forward pass through this network. This means we generate predictions.\n",
    " 6. then we compute loss of our prediction\n",
    " 7. we propagade back this loss through all the layers of this ANN. This is oficial name. But we propagate gradients.\n",
    " 8. Then we use these updates parameters for another forward pass of this MLP.\n",
    "\n",
    "At the end we use one of the standards visualization techniques for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a948377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 49ms/step - loss: 2.9750 - accuracy: 0.0000e+00 - val_loss: 2.9558 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9518 - accuracy: 0.0556 - val_loss: 2.9528 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9304 - accuracy: 0.1667 - val_loss: 2.9493 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9078 - accuracy: 0.1111 - val_loss: 2.9452 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9143 - accuracy: 0.0556 - val_loss: 2.9418 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9187 - accuracy: 0.1111 - val_loss: 2.9375 - val_accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8684 - accuracy: 0.1667 - val_loss: 2.9332 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8849 - accuracy: 0.1111 - val_loss: 2.9289 - val_accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8921 - accuracy: 0.0000e+00 - val_loss: 2.9247 - val_accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9020 - accuracy: 0.1111 - val_loss: 2.9178 - val_accuracy: 0.1429\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8808 - accuracy: 0.0556 - val_loss: 2.9123 - val_accuracy: 0.1429\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8644 - accuracy: 0.0000e+00 - val_loss: 2.9063 - val_accuracy: 0.1429\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8657 - accuracy: 0.0556 - val_loss: 2.9010 - val_accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8586 - accuracy: 0.1111 - val_loss: 2.8921 - val_accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8526 - accuracy: 0.0000e+00 - val_loss: 2.8869 - val_accuracy: 0.1429\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8683 - accuracy: 0.1111 - val_loss: 2.8852 - val_accuracy: 0.1429\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7724 - accuracy: 0.0000e+00 - val_loss: 2.8826 - val_accuracy: 0.1429\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8108 - accuracy: 0.1111 - val_loss: 2.8766 - val_accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8576 - accuracy: 0.0556 - val_loss: 2.8713 - val_accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8158 - accuracy: 0.1111 - val_loss: 2.8700 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7473 - accuracy: 0.1111 - val_loss: 2.8686 - val_accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7491 - accuracy: 0.0556 - val_loss: 2.8681 - val_accuracy: 0.1429\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7784 - accuracy: 0.0000e+00 - val_loss: 2.8659 - val_accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7611 - accuracy: 0.0000e+00 - val_loss: 2.8612 - val_accuracy: 0.1429\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6905 - accuracy: 0.0556 - val_loss: 2.8573 - val_accuracy: 0.1429\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6806 - accuracy: 0.1111 - val_loss: 2.8522 - val_accuracy: 0.1429\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6748 - accuracy: 0.0556 - val_loss: 2.8509 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6814 - accuracy: 0.0556 - val_loss: 2.8489 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6253 - accuracy: 0.1667 - val_loss: 2.8502 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6658 - accuracy: 0.0556 - val_loss: 2.8552 - val_accuracy: 0.1429\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6493 - accuracy: 0.0556 - val_loss: 2.8577 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5979 - accuracy: 0.2778 - val_loss: 2.8594 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6184 - accuracy: 0.1667 - val_loss: 2.8587 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6293 - accuracy: 0.1111 - val_loss: 2.8597 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5446 - accuracy: 0.2222 - val_loss: 2.8607 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7055 - accuracy: 0.1111 - val_loss: 2.8560 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6026 - accuracy: 0.1111 - val_loss: 2.8586 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5230 - accuracy: 0.2222 - val_loss: 2.8613 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6804 - accuracy: 0.0556 - val_loss: 2.8630 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5844 - accuracy: 0.1111 - val_loss: 2.8602 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5103 - accuracy: 0.2222 - val_loss: 2.8672 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.6621 - accuracy: 0.1111 - val_loss: 2.8744 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5661 - accuracy: 0.2222 - val_loss: 2.8809 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5779 - accuracy: 0.1111 - val_loss: 2.8899 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4968 - accuracy: 0.2222 - val_loss: 2.8909 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5159 - accuracy: 0.2222 - val_loss: 2.8926 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5777 - accuracy: 0.1111 - val_loss: 2.8971 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6670 - accuracy: 0.1667 - val_loss: 2.9111 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4751 - accuracy: 0.1111 - val_loss: 2.9142 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4766 - accuracy: 0.1111 - val_loss: 2.9223 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5847 - accuracy: 0.1667 - val_loss: 2.9219 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6040 - accuracy: 0.0556 - val_loss: 2.9248 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5474 - accuracy: 0.1111 - val_loss: 2.9208 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.5148 - accuracy: 0.1111 - val_loss: 2.9227 - val_accuracy: 0.1429\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6556 - accuracy: 0.1667 - val_loss: 2.9245 - val_accuracy: 0.1429\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5206 - accuracy: 0.1667 - val_loss: 2.9118 - val_accuracy: 0.1429\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6008 - accuracy: 0.1111 - val_loss: 2.9080 - val_accuracy: 0.1429\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5545 - accuracy: 0.1111 - val_loss: 2.9010 - val_accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.4728 - accuracy: 0.1111 - val_loss: 2.8947 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4534 - accuracy: 0.1667 - val_loss: 2.8930 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4332 - accuracy: 0.1667 - val_loss: 2.8944 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4913 - accuracy: 0.1667 - val_loss: 2.8935 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5211 - accuracy: 0.0556 - val_loss: 2.8908 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3442 - accuracy: 0.1667 - val_loss: 2.8949 - val_accuracy: 0.2857\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5511 - accuracy: 0.0000e+00 - val_loss: 2.8945 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4681 - accuracy: 0.1111 - val_loss: 2.8838 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4246 - accuracy: 0.1667 - val_loss: 2.8826 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3894 - accuracy: 0.1111 - val_loss: 2.8763 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4447 - accuracy: 0.1667 - val_loss: 2.8728 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4999 - accuracy: 0.1667 - val_loss: 2.8672 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3331 - accuracy: 0.2222 - val_loss: 2.8672 - val_accuracy: 0.2857\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3805 - accuracy: 0.1111 - val_loss: 2.8626 - val_accuracy: 0.2857\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6121 - accuracy: 0.1111 - val_loss: 2.8494 - val_accuracy: 0.2857\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3520 - accuracy: 0.2222 - val_loss: 2.8362 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2484 - accuracy: 0.2222 - val_loss: 2.8316 - val_accuracy: 0.2857\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4209 - accuracy: 0.0556 - val_loss: 2.8330 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3790 - accuracy: 0.1667 - val_loss: 2.8284 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3743 - accuracy: 0.1667 - val_loss: 2.8292 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4194 - accuracy: 0.1667 - val_loss: 2.8274 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5514 - accuracy: 0.0556 - val_loss: 2.8111 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2639 - accuracy: 0.1667 - val_loss: 2.8009 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3228 - accuracy: 0.1667 - val_loss: 2.7955 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2651 - accuracy: 0.1667 - val_loss: 2.7755 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3446 - accuracy: 0.2222 - val_loss: 2.7660 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.3652 - accuracy: 0.0556 - val_loss: 2.7605 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2730 - accuracy: 0.1667 - val_loss: 2.7584 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2801 - accuracy: 0.2222 - val_loss: 2.7550 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4062 - accuracy: 0.1667 - val_loss: 2.7520 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2548 - accuracy: 0.2222 - val_loss: 2.7518 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.3454 - accuracy: 0.0556 - val_loss: 2.7492 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4231 - accuracy: 0.1111 - val_loss: 2.7583 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4719 - accuracy: 0.1111 - val_loss: 2.7696 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2558 - accuracy: 0.2222 - val_loss: 2.7816 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2900 - accuracy: 0.1111 - val_loss: 2.7886 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2855 - accuracy: 0.1111 - val_loss: 2.7816 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1760 - accuracy: 0.3333 - val_loss: 2.7803 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.2785 - accuracy: 0.1111 - val_loss: 2.7889 - val_accuracy: 0.2857\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.2969 - accuracy: 0.1111 - val_loss: 2.7966 - val_accuracy: 0.2857\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4031 - accuracy: 0.2222 - val_loss: 2.8030 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2211 - accuracy: 0.1667 - val_loss: 2.8151 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ae0a09370>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(11, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(19, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss=categorical_crossentropy,\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "SHUFFLE = True\n",
    "\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data = (X_val, y_val), shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0e84a",
   "metadata": {},
   "source": [
    "We still have a low accuracy (bias) mostly because we still deal with a very small dataset. Loss here is a value of the cost function (losses for all predictions). Val_loss is a model variance.\n",
    "\n",
    "Because loss is lower than the validation loss (but not significantly) we can say our probability prediction model is overfitting. This is why we have employed one of the regularization techniques for neural networks - we added Dropout layer. Documentation for this approach can be found in the work of Srivastava et al. Dropout - A Simple Way to Prevent Neural Networks from Overfitting which you can find here https://jmlr.org/papers/v15/srivastava14a.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f569bad",
   "metadata": {},
   "source": [
    "**Aritificial Neural Network evaluation**\n",
    "\n",
    "Now we have to evaluate our classification model. Non-overfitting softmax regression model for us is a model with roughly same accuracy on the training, validation and test dataset. Visualization through the confusion matrix will help us evaluate model performance on these three types of the data sets.\n",
    "\n",
    "So now we're going to check our classification accuracy on the training dataset. For evaluation we use a confusion matrix. Confusion matrix consists from the ones and zeros because each organizational pattern in a dataset is represented only once. This could be changed by using other pattern descriptions, from numerous sources but for the same patterns. Ones are visible at those places, where model classified pattern according to n-gram frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a1f33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def plot_confusion_matrix(labels, pred_labels):\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = metrics.confusion_matrix(labels, pred_labels)\n",
    "    cm = metrics.ConfusionMatrixDisplay(cm, display_labels=range(18))\n",
    "    cm.plot(values_format='d', cmap='Blues', ax=ax)\n",
    "    \n",
    "train_set_probabilities_for_classes = model.predict(X_train)\n",
    "# class with a maximum probability is our predicted quality class\n",
    "train_set_predicted_classes = np.argmax(train_set_probabilities_for_classes, axis = 1)\n",
    "y_train_class = np.argmax(y_train, axis = 1)\n",
    "confusion_matrix(y_train_class, train_set_predicted_classes)\n",
    "\n",
    "plot_confusion_matrix(y_train_class, train_set_predicted_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
